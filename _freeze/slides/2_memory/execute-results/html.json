{
  "hash": "c325c11246d1cdc4b3582b54241ec60b",
  "result": {
    "markdown": "---\ntitle: Memory\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: LangChain Basics 2\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Memory\n\nConversationBufferMemory\n\nConversationBufferWindowMemory\n\nConversationTokenBufferMemory\n\nConversationSummaryMemory\n\n# Setup\n\n## Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom langchain.memory import ConversationSummaryBufferMemory\nfrom langchain.llms import OpenAI\nfrom langchain.memory import ConversationTokenBufferMemory\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import ConversationChain\nfrom langchain.chat_models import ChatOpenAI\nimport datetime\nimport warnings\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n# Conversation Buffer Memory\n\n## Setup\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nllm_model = \"gpt-3.5-turbo\"\n\nllm = ChatOpenAI(temperature=0.0, model=llm_model)\nmemory = ConversationBufferMemory()\n\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=True  # shows conversation history\n)\n```\n:::\n\n\n## Some examples\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nconversation.predict(input=\"Hi, my name is Jan\")\n```\n:::\n\n\n- \"Hello Jan! It's nice to meet you. How can I assist you today?\"\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nconversation.predict(input=\"What is 1+1?\")\n```\n:::\n\n\n- '1+1 is equal to 2.'\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nconversation.predict(input=\"What is my name?\")\n```\n:::\n\n\n- 'Your name is Jan.'\n\n## Memory buffer\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nprint(memory.buffer)\n```\n:::\n\n\n. . .\n\n```markdown\nHuman: Hi, my name is Jan\nAI: Hello Jan! It's nice to meet you. How can I assist you today?\nHuman: What is 1+1?\nAI: 1+1 is equal to 2.\nHuman: What is my name?\nAI: Your name is Jan.\n```\n. . .\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': \"Human: Hi, my name is Jan\\nAI: Hello Jan! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Jan.\"}\n\n\n## Conversational example\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nmemory = ConversationBufferMemory()\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nmemory.save_context({\"input\": \"Hi\"},\n                    {\"output\": \"What's up\"})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nprint(memory.buffer)\n```\n:::\n\n\n. . .\n\n```markdown\nHuman: Hi\nAI: What's up\n```\n\n. . .\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': \"Human: Hi\\nAI: What's up\"}\n\n## Conversational example continued\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}\n\n# Conversation Buffer Window Memory\n\n## Conversation Buffer Window Memory\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nmemory = ConversationBufferWindowMemory(k=1)\n```\n:::\n\n\n## Example\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nmemory.save_context({\"input\": \"Hi\"},\n                    {\"output\": \"What's up\"})\n\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': 'Human: Not much, just hanging\\nAI: Cool'}\n\n## Setup\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nllm = ChatOpenAI(temperature=0.0, model=llm_model)\n\nmemory = ConversationBufferWindowMemory(k=1)\n\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=False\n)\n```\n:::\n\n\n## Example {.smaller}\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nconversation.predict(input=\"Hi, my name is Jan\")\n```\n:::\n\n\n- \"Hello Jan! It's nice to meet you. How can I assist you today?\"\n\n. . .\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nconversation.predict(input=\"What is 1+1?\")\n```\n:::\n\n\n- '1+1 is equal to 2.'\n\n. . .\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nconversation.predict(input=\"What is my name?\")\n```\n:::\n\n\n- \"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\"\n\n\n# Conversation TokenBuffer Memory\n\n## Setup\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nllm = ChatOpenAI(temperature=0.0, model=llm_model)\n```\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nmemory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n```\n:::\n\n\n## Example\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nmemory.save_context({\"input\": \"AI is what?!\"},\n                    {\"output\": \"Amazing!\"})\n\nmemory.save_context({\"input\": \"Backpropagation is what?\"},\n                    {\"output\": \"Beautiful!\"})\nmemory.save_context({\"input\": \"Chatbots are what?\"},\n                    {\"output\": \"Charming!\"})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}\n\n# Conversation Summary Memory\n\n## Example\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# create a long string\nschedule = \"There is a meeting at 8am with your product team. \\\nYou will need your powerpoint presentation prepared. \\\n9am-12pm have time to work on your LangChain \\\nproject which will go quickly because Langchain is such a powerful tool. \\\nAt Noon, lunch at the italian resturant with a customer who is driving \\\nfrom over an hour away to meet you to understand the latest in AI. \\\nBe sure to bring your laptop to show the latest LLM demo.\"\n```\n:::\n\n\n## Setup\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nmemory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n```\n:::\n\n\n## Example\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nmemory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\nmemory.save_context({\"input\": \"What is on the schedule today?\"},\n                    {\"output\": f\"{schedule}\"})\n```\n:::\n\n\n## History\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': 'System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.'}\n\n## ConversationChain \n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=True\n)\n```\n:::\n\n\n## Conversation predict {.smaller}\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nconversation.predict(input=\"What would be a good demo to show?\")\n```\n:::\n\n\n- \"A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and generate interest in potential applications for the customer's business.\"\n\n\n## Memory {.smaller}\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n- {'history': \"System: The human and AI exchange greetings and discuss the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The human asks what would be a good demo to show, and the AI suggests showcasing the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. By showcasing the LLM demo, the AI can demonstrate the capabilities of AI in natural language processing and generate interest in potential applications for the customer's business.\"}\n\n\n# Acknowledgments\n\n*This tutorial is mainly based on the excellent course [\"LangChain for LLM Application Development\"](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/) provided by Harrison Chase and Andrew Ng*\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** 👍\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-basics/)**\n\n",
    "supporting": [
      "2_memory_files"
    ],
    "filters": [],
    "includes": {}
  }
}